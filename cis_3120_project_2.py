# -*- coding: utf-8 -*-
"""CIS 3120 Project 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1snMZt8j0HlBW0IDLxO_W8fb-HuKjfGZc

Web Scraping 
Wikipedia Table
"""

# importing libraries and packages
import requests
import pandas as pd
from bs4 import BeautifulSoup

# the url for the wikipedia page 
url = "https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average"
page = requests.get(url)
page.content

# parsing the url content with BeautifulSoup
soup = BeautifulSoup(page.content, "html.parser")

# finding the tabel with class wikipedia sortable
right_table=soup.find('table', class_="wikitable sortable")

# converting the str to float
DF1=pd.read_html(str(right_table)) # read_html method taken from https://medium.com/analytics-vidhya/web-scraping-a-wikipedia-table-into-a-dataframe-c52617e1f451

# convert list to dataframe
DF1=pd.DataFrame(DF1[0])

# setting the symbol column as index permanently
DF1.set_index("Symbol",inplace=True)

# replacing the % sign on Index weighting column with empty string
DF1['Index weighting']=DF1['Index weighting'].str.replace('%','')

# converting the Index weighting column to a float type
DF1['Index weighting']=DF1['Index weighting'].astype(float)

# renaming the Index weighting column
DF1.rename(columns={'Index weighting': 'Index weighting (%)'},inplace=True)

# printing the dataframe
DF1

# removing the Notes column from the dataframe
DF1.drop(columns=['Notes'],inplace=True) #known from Data Mining Course CIS 3920
DF1

"""API

"""

# importing libraries and packages
import json
import time

#signing up for free api key from alpha advantage
apikey= "XV3W9E6L66VP13KA"

# creating a list of all the symbols 
symbols= ['MMM','AXP','AMGN','AAPL','BA','CAT','CVX','CSCO','KO','DOW','GS','HD','HON','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PG','CRM','TRV','UNH','VZ','V','WBA','WMT','DIS']

#creating empty lists for dataframe
open = []
high = []
low = []
close = []
volume = []

#setting up counter for the program to sleep as the api only allows 5 calls in a minute
count=0

#creating a loop for api calls
for symbol in symbols:
  url="https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY" + "&symbol="+ symbol + "&apikey=" + apikey
  print(symbol)

  #allows 5 api calls in a minute
  if count% 5 == 0:
    time.sleep(60)
  r=requests.get(url)
  count=count+1

  #if the request is successful, prints all the values corresponding to the company
  if(r.status_code==200):
    data=r.json()

    #.append pushes the data to the empty list
    #float converts the string to decimels
    open.append(float(data["Monthly Time Series"]["2021-04-30"]['1. open']))
    print("Openeing value: " + data["Monthly Time Series"]["2021-04-30"]['1. open'])
    high.append(float(data["Monthly Time Series"]["2021-04-30"]['2. high']))
    print("Highest value: " + data["Monthly Time Series"]["2021-04-30"]['2. high'])
    low.append(float(data["Monthly Time Series"]["2021-04-30"]['3. low']))
    print("Lowest value: " + data["Monthly Time Series"]["2021-04-30"]['3. low'])
    close.append(float(data["Monthly Time Series"]["2021-04-30"]['4. close']))
    print("Closing value: " + data["Monthly Time Series"]["2021-04-30"]['4. close'])
    volume.append(float(data["Monthly Time Series"]["2021-04-30"]['5. volume']))
    print("Volume: " + data["Monthly Time Series"]["2021-04-30"]['5. volume'])
    
    #creates a new line
    print("\n")

#creating a dictionary called stock_market
stock_market={
                "Symbol": symbols,
                "Open" : open,
                "High": high,
                "Low" : low,
                "Close" : close,
                "Volume" : volume
              
}

# passing the dictionary to the dataframe 
DF2= pd.DataFrame(stock_market)

# printing the dataframe
DF2

# setting the index as symbol permanently
DF2.set_index("Symbol",inplace=True)
DF2

# merging the two dataframes together as a outer join
DF3 = pd.merge(DF1, DF2, how='outer', on= ['Symbol'] )
DF3

# Exporting the dataframe into CSV
DF3.to_csv("Stock Exchange Details.csv")

# getting the descriptive statstics on the following columns
DF3[['Index weighting (%)','Open','High','Low','Close','Volume']].describe()

# importing matplotlib module
from matplotlib import pyplot as plt

#plotting the highest rate
DF3.plot(x="Company", y ="Volume", title ='Barplot showing symbol vs highest rate', kind = "bar")

#plotting the volume rate
DF3.plot(x="Company", y ="Index weighting (%)", title ='Scatterplot showing stock symbol vs volume rate', kind = "scatter") 
plt.xticks(rotation=90) # learned from Data Visualization Course CIS 4170